{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cae293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imagehash in c:\\users\\hp\\.conda\\.conda\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hp\\.conda\\.conda\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\hp\\.conda\\.conda\\lib\\site-packages (from imagehash) (1.6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\.conda\\.conda\\lib\\site-packages (from imagehash) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\.conda\\.conda\\lib\\site-packages (from imagehash) (1.13.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install imagehash Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d036ec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\.conda\\.conda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\.conda\\.conda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\HP/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97.8M/97.8M [00:17<00:00, 5.81MB/s]\n",
      "Processing 1. Polythene: 100%|██████████| 120/120 [00:30<00:00,  3.99it/s]\n",
      "Processing 10.Mask: 100%|██████████| 129/129 [00:45<00:00,  2.86it/s]\n",
      "Processing 4. Glass: 100%|██████████| 120/120 [00:40<00:00,  3.00it/s]\n",
      "Processing 5. Wire: 100%|██████████| 120/120 [00:37<00:00,  3.23it/s]\n",
      "Processing 6. Glaves: 100%|██████████| 125/125 [00:40<00:00,  3.12it/s]\n",
      "Processing 7. Empty medicine packet: 100%|██████████| 131/131 [00:43<00:00,  3.00it/s]\n",
      "Processing 7. Shell of Malta: 100%|██████████| 126/126 [00:40<00:00,  3.07it/s]\n",
      "Processing background_ground: 100%|██████████| 2470/2470 [05:36<00:00,  7.34it/s]\n",
      "Processing Battery: 100%|██████████| 300/300 [00:38<00:00,  7.73it/s]\n",
      "Processing food_dishes: 100%|██████████| 4230/4230 [09:09<00:00,  7.70it/s]\n",
      "Processing food_items: 100%|██████████| 3862/3862 [08:19<00:00,  7.73it/s]\n",
      "Processing food_recyclable: 100%|██████████| 2571/2571 [05:43<00:00,  7.48it/s]\n",
      "Processing fruits_and_vegetables: 100%|██████████| 3187/3187 [06:53<00:00,  7.71it/s]\n",
      "Processing gauze: 100%|██████████| 393/393 [00:59<00:00,  6.62it/s]\n",
      "Processing glove_pair_latex: 100%|██████████| 330/330 [00:46<00:00,  7.13it/s]\n",
      "Processing glove_pair_nitrile: 100%|██████████| 330/330 [00:49<00:00,  6.64it/s]\n",
      "Processing glove_pair_surgery: 100%|██████████| 300/300 [00:44<00:00,  6.67it/s]\n",
      "Processing glove_single_latex: 100%|██████████| 303/303 [00:46<00:00,  6.55it/s]\n",
      "Processing glove_single_nitrile: 100%|██████████| 333/333 [00:37<00:00,  8.94it/s]\n",
      "Processing glove_single_surgery: 100%|██████████| 306/306 [00:22<00:00, 13.51it/s]\n",
      "Processing Keyboard: 100%|██████████| 300/300 [00:19<00:00, 15.37it/s]\n",
      "Processing leaves_flowers: 100%|██████████| 3238/3238 [03:46<00:00, 14.30it/s]\n",
      "Processing medical_cap: 100%|██████████| 306/306 [00:23<00:00, 12.98it/s]\n",
      "Processing medical_glasses: 100%|██████████| 318/318 [00:21<00:00, 14.54it/s]\n",
      "Processing Microwave: 100%|██████████| 300/300 [00:18<00:00, 16.11it/s]\n",
      "Processing Miscellanous_trash: 100%|██████████| 3464/3464 [03:22<00:00, 17.12it/s]\n",
      "Processing mixed: 100%|██████████| 24705/24705 [29:28<00:00, 13.97it/s]\n",
      "Processing Mobile: 100%|██████████| 300/300 [00:20<00:00, 14.33it/s]\n",
      "Processing Mouse: 100%|██████████| 300/300 [00:21<00:00, 14.28it/s]\n",
      "Processing organic_waste: 100%|██████████| 4829/4829 [05:36<00:00, 14.37it/s]\n",
      "Processing paper_cardboard: 100%|██████████| 4136/4136 [04:41<00:00, 14.68it/s]\n",
      "Processing paper_waste: 100%|██████████| 3380/3380 [03:59<00:00, 14.14it/s]\n",
      "Processing PCB: 100%|██████████| 300/300 [00:21<00:00, 13.89it/s]\n",
      "Processing plastic_containers_bottles_etc: 100%|██████████| 4700/4700 [05:18<00:00, 14.74it/s]\n",
      "Processing plastic_mixed: 100%|██████████| 2240/2240 [02:41<00:00, 13.87it/s]\n",
      "Processing Player: 100%|██████████| 300/300 [00:21<00:00, 14.05it/s]\n",
      "Processing Printer: 100%|██████████| 300/300 [00:21<00:00, 14.15it/s]\n",
      "Processing recyclable: 100%|██████████| 4056/4056 [05:02<00:00, 13.42it/s]\n",
      "Processing recyclable_metal: 100%|██████████| 1582/1582 [01:53<00:00, 13.96it/s]\n",
      "Processing shoe_cover_pair: 100%|██████████| 351/351 [00:28<00:00, 12.23it/s]\n",
      "Processing shoe_cover_single: 100%|██████████| 312/312 [00:24<00:00, 12.81it/s]\n",
      "Processing Television: 100%|██████████| 300/300 [00:21<00:00, 13.87it/s]\n",
      "Processing test_tube: 100%|██████████| 363/363 [00:28<00:00, 12.55it/s]\n",
      "Processing Textile Trash: 100%|██████████| 318/318 [00:24<00:00, 12.85it/s]\n",
      "Processing urine_bag: 100%|██████████| 300/300 [00:23<00:00, 12.52it/s]\n",
      "Processing vegetables_and_fruits: 100%|██████████| 4180/4180 [04:49<00:00, 14.42it/s]\n",
      "Processing Washing Machine: 100%|██████████| 300/300 [00:21<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL : food_dishes   |   DUPLICATE : mixed   |   Similarity: 100.00%\n",
      "ORIGINAL : food_items   |   DUPLICATE : mixed   |   Similarity: 99.99%\n",
      "ORIGINAL : food_recyclable   |   DUPLICATE : mixed   |   Similarity: 99.99%\n",
      "ORIGINAL : fruits_and_vegetables   |   DUPLICATE : mixed   |   Similarity: 99.99%\n",
      "ORIGINAL : gauze   |   DUPLICATE : glove_pair_latex   |   Similarity: 91.57%\n",
      "ORIGINAL : gauze   |   DUPLICATE : glove_single_latex   |   Similarity: 91.24%\n",
      "ORIGINAL : glove_pair_latex   |   DUPLICATE : glove_single_latex   |   Similarity: 94.46%\n",
      "ORIGINAL : glove_pair_nitrile   |   DUPLICATE : glove_single_nitrile   |   Similarity: 94.56%\n",
      "ORIGINAL : glove_pair_nitrile   |   DUPLICATE : shoe_cover_pair   |   Similarity: 91.18%\n",
      "ORIGINAL : glove_pair_nitrile   |   DUPLICATE : shoe_cover_single   |   Similarity: 92.11%\n",
      "ORIGINAL : glove_pair_surgery   |   DUPLICATE : glove_single_surgery   |   Similarity: 92.52%\n",
      "ORIGINAL : glove_single_nitrile   |   DUPLICATE : glove_single_surgery   |   Similarity: 90.31%\n",
      "ORIGINAL : glove_single_nitrile   |   DUPLICATE : shoe_cover_pair   |   Similarity: 90.57%\n",
      "ORIGINAL : glove_single_nitrile   |   DUPLICATE : shoe_cover_single   |   Similarity: 91.81%\n",
      "ORIGINAL : leaves_flowers   |   DUPLICATE : mixed   |   Similarity: 99.94%\n",
      "ORIGINAL : medical_cap   |   DUPLICATE : shoe_cover_pair   |   Similarity: 90.13%\n",
      "ORIGINAL : Miscellanous_trash   |   DUPLICATE : mixed   |   Similarity: 99.93%\n",
      "ORIGINAL : shoe_cover_pair   |   DUPLICATE : shoe_cover_single   |   Similarity: 93.94%\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# MEMORY-EFFICIENT DUPLICATE FOLDER CHECK (RESNET50)\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "# ------------------------------\n",
    "# Load Pretrained ResNet50\n",
    "# ------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # remove classifier\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ------------------------------\n",
    "# Convert image → embedding\n",
    "# ------------------------------\n",
    "def get_embedding(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    img_t = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = model(img_t)\n",
    "\n",
    "    emb = emb.view(-1)\n",
    "    emb = normalize(emb, dim=0)\n",
    "    return emb.cpu().numpy()\n",
    "\n",
    "# ------------------------------\n",
    "# Process single folder\n",
    "# ------------------------------\n",
    "def compute_folder_embeddings(folder_path, save_path):\n",
    "    if os.path.exists(save_path):\n",
    "        return np.load(save_path)\n",
    "\n",
    "    embeddings = []\n",
    "    image_files = [f for f in os.listdir(folder_path)\n",
    "                   if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "\n",
    "    for img in tqdm(image_files, desc=f\"Processing {os.path.basename(folder_path)}\"):\n",
    "        full = os.path.join(folder_path, img)\n",
    "        emb = get_embedding(full)\n",
    "        if emb is not None:\n",
    "            embeddings.append(emb)\n",
    "\n",
    "    embeddings = np.array(embeddings)\n",
    "    np.save(save_path, embeddings)\n",
    "    return embeddings\n",
    "\n",
    "# ------------------------------\n",
    "# Folder similarity (cosine)\n",
    "# ------------------------------\n",
    "def folder_similarity(emb1, emb2):\n",
    "    if len(emb1) == 0 or len(emb2) == 0:\n",
    "        return 0\n",
    "\n",
    "    sims = []\n",
    "    emb2_T = emb2.T\n",
    "\n",
    "    for e1 in emb1:\n",
    "        cos = np.dot(e1, emb2_T).max()   # best match\n",
    "        sims.append(cos)\n",
    "\n",
    "    return np.mean(sims)\n",
    "\n",
    "# ------------------------------\n",
    "# DETECT FOLDERS WITH >90% DUPLICATION\n",
    "# ------------------------------\n",
    "def detect_duplicate_folders(root_path, threshold=0.90):\n",
    "    folders = [os.path.join(root_path, d) for d in os.listdir(root_path)\n",
    "               if os.path.isdir(os.path.join(root_path, d))]\n",
    "\n",
    "    folder_embeddings = {}\n",
    "    duplicates = []\n",
    "\n",
    "    # Step 1: compute/load embeddings\n",
    "    for f in folders:\n",
    "        save_path = f\"{f}_embeddings.npy\"\n",
    "        emb = compute_folder_embeddings(f, save_path)\n",
    "        folder_embeddings[f] = emb\n",
    "\n",
    "    # Step 2: compare folders\n",
    "    for i in range(len(folders)):\n",
    "        for j in range(i+1, len(folders)):\n",
    "            f1, f2 = folders[i], folders[j]\n",
    "\n",
    "            sim = folder_similarity(folder_embeddings[f1],\n",
    "                                    folder_embeddings[f2])\n",
    "\n",
    "            if sim >= threshold:\n",
    "                duplicates.append((os.path.basename(f1),\n",
    "                                   os.path.basename(f2),\n",
    "                                   sim))\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# RUN\n",
    "# ===============================\n",
    "\n",
    "root_path = r\"E:\\merged_waste_dataset\"   # <-- CHANGE THIS\n",
    "\n",
    "duplicates = detect_duplicate_folders(root_path)\n",
    "\n",
    "for f1, f2, sim in duplicates:\n",
    "    print(f\"ORIGINAL : {f1}   |   DUPLICATE : {f2}   |   Similarity: {sim*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86792e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
